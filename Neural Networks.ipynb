{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial \n",
    "#from linear_algebra import dot\n",
    "import math, random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron_output(weights, bias, x):\n",
    "    \"\"\"returns 1 if the perceptron 'fires', 0 if not\"\"\"\n",
    "    return step_function(dot(weights, x) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagate(network, input_vector, target):\n",
    "\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "\n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                      dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patch(x, y, hatch, color):\n",
    "    \"\"\"return a matplotlib 'patch' object with the specified\n",
    "    location, crosshatch pattern, and color\"\"\"\n",
    "    return matplotlib.patches.Rectangle((x - 0.5, y - 0.5), 1, 1,\n",
    "                                        hatch=hatch, fill=False, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_weights(neuron_idx):\n",
    "    weights = network[0][neuron_idx]\n",
    "    abs_weights = [abs(weight) for weight in weights]\n",
    "\n",
    "    grid = [abs_weights[row:(row+5)] # turn the weights into a 5x5 grid\n",
    "            for row in range(0,25,5)] # [weights[0:5], ..., weights[20:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_weights(neuron_idx):\n",
    "    weights = network[0][neuron_idx]\n",
    "    abs_weights = [abs(weight) for weight in weights]\n",
    "\n",
    "    grid = [abs_weights[row:(row+5)] # turn the weights into a 5x5 grid\n",
    "            for row in range(0,25,5)] # [weights[0:5], ..., weights[20:25]]\n",
    "\n",
    "    ax = plt.gca() # to use hatching, we'll need the axis\n",
    "\n",
    "    ax.imshow(grid, # here same as plt.imshow\n",
    "              cmap=matplotlib.cm.binary, # use white-black color scale\n",
    "              interpolation='none') # plot blocks as blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-645808bada80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cross-hatch the negative weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "# cross-hatch the negative weights\n",
    "\n",
    "weights = network[0][neuron_idx]\n",
    "\n",
    "for i in range(5): # row\n",
    "    for j in range(5): # column\n",
    "        if weights[5*i + j] < 0: # row i, column j = weights[5*i + j]\n",
    "                # add black and white hatches, so visible whether dark or light\n",
    "            ax.add_patch(patch(j, i, '/', \"white\"))\n",
    "            ax.add_patch(patch(j, i, '\\\\', \"black\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
